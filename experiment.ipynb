{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Assignment 2: Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing this script, I referenced\n",
    " Hayes, G. (2019). mlrose: Machine Learning, Randomized Optimization and SEarch package for Python. https://github.com/gkhayes/mlrose \n",
    " and also https://github.com/hiive/mlrose\n",
    "\n",
    "mlrose is a Python package for applying some of the most common randomized optimization and search algorithms to a range of different optimization problems, over both discrete- and continuous-valued parameter spaces. This notebook contains the examples used in the mlrose tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import mlrose_hiive as mlrose\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:  Fill the Knapsack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(fitness_curve, name=\"unknown\"):\n",
    "    plt.title(\"Line graph\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Fitness Score\")\n",
    "    plt.plot(range(0,len(fitness_curve)), fitness_curve[:,0], color =\"red\")\n",
    "    plt.savefig(f'charts/{name}_fitness.png', bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.title(\"Evaluations per Iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"# Evaluations\")\n",
    "    plt.plot(range(0,len(fitness_curve)), fitness_curve[:,1], color =\"red\")\n",
    "    plt.savefig(f'charts/{name}_evaluations.png', bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def do_it_all(algorithm, name=\"Unknown\", weight = []):\n",
    "    tic = time.perf_counter()\n",
    "    best_state, best_fitness, fitness_curve = algorithm()\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"{name} completed in {toc - tic:0.4f} seconds\")\n",
    "    print(f'{name} thinks best fitness/value is ', best_fitness)\n",
    "    total_weight = 0\n",
    "    for index, item in enumerate(best_state):\n",
    "        if item == 1:\n",
    "            total_weight += weight[index]\n",
    "        elif item != 0:\n",
    "            print('idk what this is')\n",
    "            print(item)\n",
    "            raise Exception(\"you should not get here\")\n",
    "    print(f'{name} total weight packed is {total_weight}')\n",
    "    plot(fitness_curve, f'{name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=========================\n",
      "Using 5 Items...\n",
      "=========================\n",
      "Total weight of items: 68\n",
      "Max Weight Allowed:  40.8\n",
      "knapsack_random_hill_climbing_5 completed in 0.2558 seconds\n",
      "knapsack_random_hill_climbing_5 thinks best fitness/value is  88.0\n",
      "knapsack_random_hill_climbing_5 total weight packed is 34\n",
      "knapsack_simulated_annealing_5 completed in 0.0017 seconds\n",
      "knapsack_simulated_annealing_5 thinks best fitness/value is  44.0\n",
      "knapsack_simulated_annealing_5 total weight packed is 32\n",
      "knapsack_genetic_algorithm_5 completed in 1.2126 seconds\n",
      "knapsack_genetic_algorithm_5 thinks best fitness/value is  88.0\n",
      "knapsack_genetic_algorithm_5 total weight packed is 34\n",
      "knapsack_mimic_5 completed in 0.0699 seconds\n",
      "knapsack_mimic_5 thinks best fitness/value is  88.0\n",
      "knapsack_mimic_5 total weight packed is 34\n",
      "\n",
      "\n",
      "=========================\n",
      "Using 10 Items...\n",
      "=========================\n",
      "Total weight of items: 204\n",
      "Max Weight Allowed:  122.39999999999999\n",
      "knapsack_random_hill_climbing_10 completed in 0.2702 seconds\n",
      "knapsack_random_hill_climbing_10 thinks best fitness/value is  224.0\n",
      "knapsack_random_hill_climbing_10 total weight packed is 123\n",
      "knapsack_simulated_annealing_10 completed in 0.0018 seconds\n",
      "knapsack_simulated_annealing_10 thinks best fitness/value is  147.0\n",
      "knapsack_simulated_annealing_10 total weight packed is 121\n",
      "knapsack_genetic_algorithm_10 completed in 1.1759 seconds\n",
      "knapsack_genetic_algorithm_10 thinks best fitness/value is  224.0\n",
      "knapsack_genetic_algorithm_10 total weight packed is 123\n",
      "knapsack_mimic_10 completed in 0.2054 seconds\n",
      "knapsack_mimic_10 thinks best fitness/value is  224.0\n",
      "knapsack_mimic_10 total weight packed is 123\n",
      "\n",
      "\n",
      "=========================\n",
      "Using 50 Items...\n",
      "=========================\n",
      "Total weight of items: 1028\n",
      "Max Weight Allowed:  616.8\n",
      "knapsack_random_hill_climbing_50 completed in 0.4014 seconds\n",
      "knapsack_random_hill_climbing_50 thinks best fitness/value is  928.0\n",
      "knapsack_random_hill_climbing_50 total weight packed is 617\n",
      "knapsack_simulated_annealing_50 completed in 0.0021 seconds\n",
      "knapsack_simulated_annealing_50 thinks best fitness/value is  845.0\n",
      "knapsack_simulated_annealing_50 total weight packed is 615\n",
      "knapsack_genetic_algorithm_50 completed in 1.8011 seconds\n",
      "knapsack_genetic_algorithm_50 thinks best fitness/value is  1074.0\n",
      "knapsack_genetic_algorithm_50 total weight packed is 616\n",
      "knapsack_mimic_50 completed in 13.1146 seconds\n",
      "knapsack_mimic_50 thinks best fitness/value is  1039.0\n",
      "knapsack_mimic_50 total weight packed is 616\n",
      "\n",
      "\n",
      "=========================\n",
      "Using 100 Items...\n",
      "=========================\n",
      "Total weight of items: 2756\n",
      "Max Weight Allowed:  1653.6\n",
      "knapsack_random_hill_climbing_100 completed in 0.4964 seconds\n",
      "knapsack_random_hill_climbing_100 thinks best fitness/value is  1562.0\n",
      "knapsack_random_hill_climbing_100 total weight packed is 1650\n",
      "knapsack_simulated_annealing_100 completed in 0.0033 seconds\n",
      "knapsack_simulated_annealing_100 thinks best fitness/value is  1455.0\n",
      "knapsack_simulated_annealing_100 total weight packed is 1653\n",
      "knapsack_genetic_algorithm_100 completed in 5.2412 seconds\n",
      "knapsack_genetic_algorithm_100 thinks best fitness/value is  1941.0\n",
      "knapsack_genetic_algorithm_100 total weight packed is 1652\n",
      "knapsack_mimic_100 completed in 67.2828 seconds\n",
      "knapsack_mimic_100 thinks best fitness/value is  1893.0\n",
      "knapsack_mimic_100 total weight packed is 1650\n",
      "\n",
      "\n",
      "=========================\n",
      "Using 200 Items...\n",
      "=========================\n",
      "Total weight of items: 5006\n",
      "Max Weight Allowed:  3003.6\n",
      "knapsack_random_hill_climbing_200 completed in 0.5294 seconds\n",
      "knapsack_random_hill_climbing_200 thinks best fitness/value is  3518.0\n",
      "knapsack_random_hill_climbing_200 total weight packed is 3003\n",
      "knapsack_simulated_annealing_200 completed in 0.0019 seconds\n",
      "knapsack_simulated_annealing_200 thinks best fitness/value is  2992.0\n",
      "knapsack_simulated_annealing_200 total weight packed is 2786\n",
      "knapsack_genetic_algorithm_200 completed in 4.1490 seconds\n",
      "knapsack_genetic_algorithm_200 thinks best fitness/value is  4437.0\n",
      "knapsack_genetic_algorithm_200 total weight packed is 3002\n"
     ]
    }
   ],
   "source": [
    "# Initialize fitness function object using pre-defined class\n",
    "'''\n",
    "Fitness function for Knapsack optimization problem. Given a set of n\n",
    "items, where item i has known weight :math:`w_{i}` and known value\n",
    ":math:`v_{i}`; and maximum knapsack capacity, :math:`W`, the Knapsack\n",
    "fitness function evaluates the fitness of a state vector\n",
    ":math:`x = [x_{0}, x_{1}, \\ldots, x_{n-1}]` as:\n",
    "'''\n",
    "# https://en.wikipedia.org/wiki/Knapsack_problem\n",
    "# We're trying to get to the highest value possible, without going over our weight limit\n",
    "\n",
    "ns = [5,10,50,100,200] # items in our knapsack\n",
    "for n in ns:\n",
    "    print('\\n\\n=========================')\n",
    "    print(f'Using {n} Items...')\n",
    "    print('=========================')\n",
    "    weights = np.random.randint(1,50,size=(n))\n",
    "    values =  np.random.randint(1,50,size=(n))\n",
    "    max_weight_pct = 0.6 # so we can only hold 60% of our total weight for items we're trying to fit\n",
    "    print(f'Total weight of items: {np.sum(weights)}')\n",
    "    print('Max Weight Allowed: ', np.sum(weights)*max_weight_pct)\n",
    "    fitness = mlrose.Knapsack(weights, values, max_weight_pct)\n",
    "\n",
    "    plt.title(\"Evaluations per Iteration\")\n",
    "    plt.xlabel(\"Weights\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.scatter(weights, values)\n",
    "    plt.savefig(f'charts/knapsack_problem.png', bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "    # Now that we've defined the problem, lets see which one can solve it best\n",
    "\n",
    "    # basically have a seed state so we can reproduce\n",
    "    init_state = 5\n",
    "    alg = lambda: mlrose.random_hill_climb(problem, \n",
    "                                           max_attempts=100, \n",
    "                                           restarts=100, \n",
    "                                           curve=True, \n",
    "                                           random_state = init_state)\n",
    "    do_it_all(alg, f'knapsack_random_hill_climbing_{n}', weights)\n",
    "\n",
    "    schedule = mlrose.ExpDecay()\n",
    "    alg = lambda: mlrose.simulated_annealing(problem, \n",
    "                                             schedule = schedule, \n",
    "                                             max_attempts = 100,\n",
    "                                             curve=True, \n",
    "                                             max_iters = 50, \n",
    "                                             random_state = init_state)\n",
    "    do_it_all(alg, f'knapsack_simulated_annealing_{n}', weights)\n",
    "\n",
    "    alg = lambda: mlrose.genetic_alg(problem, \n",
    "                                     pop_size=200, \n",
    "                                     pop_breed_percent=0.75,\n",
    "                                     elite_dreg_ratio=0.99, \n",
    "                                     minimum_elites=0,\n",
    "                                     minimum_dregs=0,\n",
    "                                     mutation_prob=0.1,\n",
    "                                     max_attempts=100,\n",
    "                                     max_iters=1000,\n",
    "                                     curve=True, \n",
    "                                     random_state=init_state,\n",
    "                                     state_fitness_callback=None, \n",
    "                                     callback_user_info=None,\n",
    "                                     hamming_factor=0.0, \n",
    "                                     hamming_decay_factor=None)\n",
    "    \n",
    "    do_it_all(alg, f'knapsack_genetic_algorithm_{n}', weights)\n",
    "\n",
    "\n",
    "    alg = lambda: mlrose.mimic(problem, \n",
    "                               pop_size=200, \n",
    "                               keep_pct=0.2, \n",
    "                               max_attempts=5,\n",
    "                               curve=True, \n",
    "                               random_state=init_state, \n",
    "                               state_fitness_callback=None,\n",
    "                               callback_user_info=None, noise=0.0)\n",
    "    do_it_all(alg, f'knapsack_mimic_{n}', weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Six Peaks Using Custom Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fitness function object using pre-defined class\n",
    "\n",
    "n = 50 \n",
    "fitness = mlrose.SixPeaks(t_pct=0.15)\n",
    "\n",
    "problem = mlrose.DiscreteOpt(length=n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "# Now that we've defined the problem, lets see which one can solve it best\n",
    "\n",
    "# Randomized Hill Climbing\n",
    "# basically have a seed state so we can reproduce\n",
    "init_state = 5\n",
    "best_state, best_fitness, fitness_curve = mlrose.random_hill_climb(problem, max_attempts=100, restarts=50, curve=True, \n",
    "                                                                   random_state=init_state)\n",
    "\n",
    "print('Random Hill Climb thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)\n",
    "\n",
    "schedule = mlrose.ExpDecay()\n",
    "best_state, best_fitness, fitness_curve = mlrose.simulated_annealing(problem, schedule = schedule, max_attempts = 100,\n",
    "                                                                     curve=True, max_iters = 50, random_state = init_state)\n",
    "\n",
    "print('Simulated Annealing thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)\n",
    "\n",
    "\n",
    "best_state, best_fitness, fitness_curve = mlrose.genetic_alg(problem, pop_size=200, pop_breed_percent=0.75,\n",
    "                                                             elite_dreg_ratio=0.99, minimum_elites=0,\n",
    "                                                             minimum_dregs=0, mutation_prob=0.1, max_attempts=100,\n",
    "                                                             max_iters=1000, curve=True, random_state=init_state,\n",
    "                                                             state_fitness_callback=None, callback_user_info=None,\n",
    "                                                             hamming_factor=0.0, hamming_decay_factor=None)\n",
    "\n",
    "print('Genetic Algorithm thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)\n",
    "\n",
    "\n",
    "best_state, best_fitness, fitness_curve = mlrose.mimic(problem, pop_size=200, keep_pct=0.2, \n",
    "                                                       max_attempts=10 ,\n",
    "                                                       curve=True, random_state=init_state, \n",
    "                                                       state_fitness_callback=None, \n",
    "                                                       callback_user_info=None, noise=0.0)\n",
    "\n",
    "print('MIMIC thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example 3: Travelling Salesperson Using Coordinate-Defined Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of city coordinates\n",
    "n = 40\n",
    "coords_list = []\n",
    "for i in range(n):\n",
    "    coords_list.append((np.random.randint(50),np.random.randint(50)))\n",
    "\n",
    "# Initialize fitness function object using coords_list\n",
    "fitness_coords = mlrose.TravellingSales(coords = coords_list)\n",
    "# Define optimization problem object\n",
    "problem = mlrose.TSPOpt(length = len(coords_list), fitness_fn = fitness_coords, maximize = True)\n",
    "\n",
    "\n",
    "# Now that we've defined the problem, lets see which one can solve it best\n",
    "\n",
    "# Randomized Hill Climbing\n",
    "# basically have a seed state so we can reproduce\n",
    "init_state = 5\n",
    "best_state, best_fitness, fitness_curve = mlrose.random_hill_climb(problem, max_attempts=100, restarts=50, curve=True, \n",
    "                                                                   random_state=init_state)\n",
    "\n",
    "print('Random Hill Climb thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)\n",
    "\n",
    "schedule = mlrose.ExpDecay()\n",
    "best_state, best_fitness, fitness_curve = mlrose.simulated_annealing(problem, schedule = schedule, max_attempts = 100,\n",
    "                                                                     curve=True, max_iters = 50, random_state = init_state)\n",
    "\n",
    "print('Simulated Annealing thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)\n",
    "\n",
    "best_state, best_fitness, fitness_curve = mlrose.genetic_alg(problem, pop_size=200, pop_breed_percent=0.75,\n",
    "                                                             elite_dreg_ratio=0.99, minimum_elites=0,\n",
    "                                                             minimum_dregs=0, mutation_prob=0.1, max_attempts=100,\n",
    "                                                             max_iters=1000, curve=True, random_state=init_state,\n",
    "                                                             state_fitness_callback=None, callback_user_info=None,\n",
    "                                                             hamming_factor=0.0, hamming_decay_factor=None)\n",
    "\n",
    "print('Genetic Algorithm thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)\n",
    "\n",
    "best_state, best_fitness, fitness_curve = mlrose.mimic(problem, pop_size=200, keep_pct=0.2, \n",
    "                                                       max_attempts=10 ,\n",
    "                                                       curve=True, random_state=init_state, \n",
    "                                                       state_fitness_callback=None, \n",
    "                                                       callback_user_info=None, noise=0.0)\n",
    "\n",
    "print('MIMIC thinks best fitness is ', best_fitness)\n",
    "plot(fitness_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Fitting a Neural Network to the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "df = pd.read_csv(\"data/heart.csv\")\n",
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    " # https://www.kaggle.com/ronitf/heart-disease-uci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(np.array(y_train).reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(np.array(y_test).reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network object and fit object - attempt 1\n",
    "nn_model1 = mlrose.NeuralNetwork(hidden_nodes = [2], activation ='relu', \n",
    "                                 algorithm ='random_hill_climb', \n",
    "                                 max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                 learning_rate = 0.0001, early_stopping = True, \n",
    "                                 clip_max = 5, max_attempts = 100, random_state = 3)\n",
    "\n",
    "nn_model1.fit(X_train_scaled, y_train_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = nn_model1.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(y_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = nn_model1.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "\n",
    "print(y_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network object and fit object - attempt 2\n",
    "nn_model2 = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \n",
    "                                 algorithm = 'gradient_descent', \n",
    "                                 max_iters = 1000, bias = True, is_classifier = True, \n",
    "                                 learning_rate = 0.0001, early_stopping = True, \n",
    "                                 clip_max = 5, max_attempts = 100, random_state = 3)\n",
    "\n",
    "nn_model2.fit(X_train_scaled, y_train_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = nn_model2.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(y_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = nn_model2.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "\n",
    "print(y_test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdd7e1c2594becc0f0730fd88e427749c52dec6ea015258dec14119a99cf0656"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
