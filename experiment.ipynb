{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Assignment 2: Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing this script, I referenced\n",
    " Hayes, G. (2019). mlrose: Machine Learning, Randomized Optimization and SEarch package for Python. https://github.com/gkhayes/mlrose \n",
    " and also https://github.com/hiive/mlrose\n",
    "\n",
    "mlrose is a Python package for applying some of the most common randomized optimization and search algorithms to a range of different optimization problems, over both discrete- and continuous-valued parameter spaces. This notebook contains the examples used in the mlrose tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "import mlrose_hiive as mlrose\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:  Fill the Knapsack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    def __init__(self,n, problem_name, algs, alg_names):\n",
    "        self.n = n\n",
    "        self.name = problem_name\n",
    "        fig1, ax1 = plt.subplots()\n",
    "#         ax1.title = \"Score Per Iteration\"\n",
    "        ax1.set_ylabel(\"Fitness score\")\n",
    "        ax1.set_xlabel(\"Iteration\")\n",
    "        self.fig1 = fig1\n",
    "        self.ax1 = ax1\n",
    "        \n",
    "        fig2, ax2 = plt.subplots()\n",
    "#         ax2.title = \"Evals Per Iteration\"\n",
    "        ax2.set_ylabel(\"Fitness Evals\")\n",
    "        ax2.set_xlabel(\"Iterations\")\n",
    "        self.fig2 = fig2\n",
    "        self.ax2 = ax2\n",
    "        \n",
    "        self.algs = algs\n",
    "        self.names = alg_names\n",
    "        self.times = []\n",
    "        self.best_fitnesses = []\n",
    "        \n",
    "    def run(self):\n",
    "        for algorithm, name in zip(self.algs,self.names):\n",
    "            print(f'starting {name}....')\n",
    "            tic = time.perf_counter()\n",
    "            best_state, best_fitness, fitness_curve = algorithm()\n",
    "            toc = time.perf_counter()\n",
    "#             print(f\"{name} completed in {toc - tic:0.4f} seconds\")\n",
    "#             print(f'{name} found best fitness/value: ', best_fitness, '\\n')\n",
    "            \n",
    "            self.times.append(toc-tic)\n",
    "            self.best_fitnesses.append(best_fitness)\n",
    "            self.plot_curve(fitness_curve, f'{name}')\n",
    "        \n",
    "        self.fig1.legend(loc=4)\n",
    "        self.fig2.legend(loc=4)\n",
    "        self.fig1.savefig(f'charts/{self.name}_{n}_items.png', bbox_inches='tight')\n",
    "        self.fig2.savefig(f'charts/{self.name}_{n}_items_evals.png', bbox_inches='tight')\n",
    "        self.fig1.clf()\n",
    "        self.fig2.clf()\n",
    "    \n",
    "    def print_stats(self):\n",
    "        for name, time, best_fitness in zip(self.names, self.times, self.best_fitnesses):\n",
    "            print(f'{name} had \\n\\tTime: {time:0.4f} seconds\\n\\tFitness Score: {best_fitness}')\n",
    "    def plot_curve(self, fitness_curve, name):\n",
    "        self.ax1.plot(range(0,len(fitness_curve)), fitness_curve[:,0], label=f'{name}')\n",
    "        self.ax2.plot(range(0,len(fitness_curve)), fitness_curve[:,1], label=f'{name}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "starting n = 50...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0015 seconds\n",
      "\tFitness Score: 833.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.0016 seconds\n",
      "\tFitness Score: 842.0\n",
      "genetic_algorithm had \n",
      "\tTime: 0.5562 seconds\n",
      "\tFitness Score: 1140.0\n",
      "mimic had \n",
      "\tTime: 0.4389 seconds\n",
      "\tFitness Score: 1119.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 100...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0014 seconds\n",
      "\tFitness Score: 1568.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.0015 seconds\n",
      "\tFitness Score: 1546.0\n",
      "genetic_algorithm had \n",
      "\tTime: 1.0966 seconds\n",
      "\tFitness Score: 2081.0\n",
      "mimic had \n",
      "\tTime: 0.9030 seconds\n",
      "\tFitness Score: 2035.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 200...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0034 seconds\n",
      "\tFitness Score: 3264.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.0018 seconds\n",
      "\tFitness Score: 2703.0\n",
      "genetic_algorithm had \n",
      "\tTime: 1.4800 seconds\n",
      "\tFitness Score: 4401.0\n",
      "mimic had \n",
      "\tTime: 3.0820 seconds\n",
      "\tFitness Score: 4197.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 1000...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0101 seconds\n",
      "\tFitness Score: 14994.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.0128 seconds\n",
      "\tFitness Score: 14784.0\n",
      "genetic_algorithm had \n",
      "\tTime: 5.4875 seconds\n",
      "\tFitness Score: 21298.0\n",
      "mimic had \n",
      "\tTime: 65.9844 seconds\n",
      "\tFitness Score: 18751.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize fitness function object using pre-defined class\n",
    "'''\n",
    "Fitness function for Knapsack optimization problem. Given a set of n\n",
    "items, where item i has known weight :math:`w_{i}` and known value\n",
    ":math:`v_{i}`; and maximum knapsack capacity, :math:`W`, the Knapsack\n",
    "fitness function evaluates the fitness of a state vector\n",
    ":math:`x = [x_{0}, x_{1}, \\ldots, x_{n-1}]` as:\n",
    "'''\n",
    "# https://en.wikipedia.org/wiki/Knapsack_problem\n",
    "# We're trying to get to the highest value possible, without going over our weight limit\n",
    "\n",
    "ns = [50,100,200,1000] # items in our knapsack\n",
    "weights = []\n",
    "values = []\n",
    "fitnesses = []\n",
    "init_states = []\n",
    "for n in ns:\n",
    "    weight = (np.random.randint(1,50,size=(n)))\n",
    "    value = (np.random.randint(1,50,size=(n)))\n",
    "    init_state = np.random.randint(0,1,size=(n))\n",
    "    init_states.append(init_state)\n",
    "    max_weight_pct = 0.6 # so we can only hold 60% of our total weight for items we're trying to fit\n",
    "    fitnesses.append(mlrose.Knapsack(weight, value, max_weight_pct))\n",
    "    weights.append(weight)\n",
    "    values.append(value)\n",
    "\n",
    "# basically have a seed state so we can reproduce\n",
    "random_state = 5\n",
    "for weight, value, fitness, n, init_state in zip(weights, values, fitnesses, ns, init_states):\n",
    "    print('=====================')\n",
    "    print(f'starting n = {n}...')\n",
    "    algs = []\n",
    "    alg_names = []\n",
    "    \n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.random_hill_climb(problem, curve=True, random_state = random_state))\n",
    "\n",
    "    alg_names.append('random_hill_climbing')\n",
    "    \n",
    "    \n",
    "\n",
    "    schedule = mlrose.GeomDecay(.01,0.0001)\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.simulated_annealing(problem, schedule=schedule, curve=True, random_state = random_state))\n",
    "    alg_names.append('simulated_annealing')\n",
    "    \n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.genetic_alg(problem, curve=True, random_state=random_state))\n",
    "    \n",
    "    alg_names.append('genetic_algorithm')\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.mimic(problem,\n",
    "                                     curve=True, \n",
    "                                     random_state=random_state))\n",
    "    alg_names.append('mimic')\n",
    "    \n",
    "    thing = Runner(n, 'knapsack', algs, alg_names)\n",
    "    thing.run()\n",
    "    thing.print_stats()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Six Peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "starting n = 50...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0003 seconds\n",
      "\tFitness Score: 6.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.0074 seconds\n",
      "\tFitness Score: 76.0\n",
      "genetic_algorithm had \n",
      "\tTime: 0.7436 seconds\n",
      "\tFitness Score: 83.0\n",
      "mimic had \n",
      "\tTime: 0.2450 seconds\n",
      "\tFitness Score: 16.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 100...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0003 seconds\n",
      "\tFitness Score: 1.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.0989 seconds\n",
      "\tFitness Score: 63.0\n",
      "genetic_algorithm had \n",
      "\tTime: 0.9114 seconds\n",
      "\tFitness Score: 136.0\n",
      "mimic had \n",
      "\tTime: 0.7808 seconds\n",
      "\tFitness Score: 22.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 200...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0003 seconds\n",
      "\tFitness Score: 4.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.4089 seconds\n",
      "\tFitness Score: 99.0\n",
      "genetic_algorithm had \n",
      "\tTime: 0.2936 seconds\n",
      "\tFitness Score: 24.0\n",
      "mimic had \n",
      "\tTime: 2.7412 seconds\n",
      "\tFitness Score: 27.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 500...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0006 seconds\n",
      "\tFitness Score: 1.0\n",
      "simulated_annealing had \n",
      "\tTime: 1.9125 seconds\n",
      "\tFitness Score: 202.0\n",
      "genetic_algorithm had \n",
      "\tTime: 0.8492 seconds\n",
      "\tFitness Score: 46.0\n",
      "mimic had \n",
      "\tTime: 18.9235 seconds\n",
      "\tFitness Score: 33.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize fitness function object using pre-defined class\n",
    "\n",
    "ns = [50,100,200,500] # items in our knapsack\n",
    "\n",
    "fitnesses = []\n",
    "for n in ns:\n",
    "    fitnesses.append(mlrose.SixPeaks(t_pct=0.20))\n",
    "\n",
    "\n",
    "# basically have a seed state so we can reproduce\n",
    "\n",
    "\n",
    "# basically have a seed state so we can reproduce\n",
    "random_state = 5\n",
    "for fitness, n in zip(fitnesses, ns):\n",
    "    print('=====================')\n",
    "    print(f'starting n = {n}...')\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs = []\n",
    "    alg_names = []\n",
    "    \n",
    "    algs.append(lambda: mlrose.random_hill_climb(problem, curve=True, random_state = random_state))\n",
    "\n",
    "    alg_names.append('random_hill_climbing')\n",
    "    \n",
    "    \n",
    "\n",
    "    schedule = mlrose.GeomDecay(.01,0.001)\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.simulated_annealing(problem,schedule=schedule, curve=True, random_state = random_state))\n",
    "    alg_names.append('simulated_annealing')\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.genetic_alg(problem, curve=True, random_state=random_state))\n",
    "    \n",
    "    alg_names.append('genetic_algorithm')\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.mimic(problem,\n",
    "                                     curve=True, \n",
    "                                     random_state=random_state))\n",
    "    alg_names.append('mimic')\n",
    "    \n",
    "    thing = Runner(n, 'six_peaks', algs, alg_names)\n",
    "    thing.run()\n",
    "    thing.print_stats()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example 3: Queens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "starting n = 50...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0437 seconds\n",
      "\tFitness Score: 86.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.2460 seconds\n",
      "\tFitness Score: 90.0\n",
      "genetic_algorithm had \n",
      "\tTime: 3.0760 seconds\n",
      "\tFitness Score: 88.0\n",
      "mimic had \n",
      "\tTime: 3.5402 seconds\n",
      "\tFitness Score: 93.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 100...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0486 seconds\n",
      "\tFitness Score: 154.0\n",
      "simulated_annealing had \n",
      "\tTime: 0.6331 seconds\n",
      "\tFitness Score: 181.0\n",
      "genetic_algorithm had \n",
      "\tTime: 13.8467 seconds\n",
      "\tFitness Score: 178.0\n",
      "mimic had \n",
      "\tTime: 9.1183 seconds\n",
      "\tFitness Score: 184.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 200...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.0740 seconds\n",
      "\tFitness Score: 307.0\n",
      "simulated_annealing had \n",
      "\tTime: 1.7781 seconds\n",
      "\tFitness Score: 354.0\n",
      "genetic_algorithm had \n",
      "\tTime: 26.2493 seconds\n",
      "\tFitness Score: 338.0\n",
      "mimic had \n",
      "\tTime: 23.6326 seconds\n",
      "\tFitness Score: 363.0\n",
      "\n",
      "\n",
      "=====================\n",
      "starting n = 500...\n",
      "starting random_hill_climbing....\n",
      "starting simulated_annealing....\n",
      "starting genetic_algorithm....\n",
      "starting mimic....\n",
      "random_hill_climbing had \n",
      "\tTime: 0.3855 seconds\n",
      "\tFitness Score: 762.0\n",
      "simulated_annealing had \n",
      "\tTime: 18.3536 seconds\n",
      "\tFitness Score: 917.0\n",
      "genetic_algorithm had \n",
      "\tTime: 48.5405 seconds\n",
      "\tFitness Score: 800.0\n",
      "mimic had \n",
      "\tTime: 92.8594 seconds\n",
      "\tFitness Score: 883.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns = [50,100,200,500] # items in our knapsack\n",
    "\n",
    "fitnesses = []\n",
    "init_coords = []\n",
    "for n in ns:\n",
    "    fitnesses.append(mlrose.Queens())\n",
    "\n",
    "\n",
    "# basically have a seed state so we can reproduce\n",
    "random_state = 5\n",
    "times = []\n",
    "for fitness, n in zip(fitnesses, ns):\n",
    "    print('=====================')\n",
    "    print(f'starting n = {n}...')\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs = []\n",
    "    alg_names = []\n",
    "    \n",
    "    algs.append(lambda: mlrose.random_hill_climb(problem, curve=True, random_state = random_state))\n",
    "\n",
    "    alg_names.append('random_hill_climbing')\n",
    "    \n",
    "    schedule = mlrose.GeomDecay(.01,0.0001)\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.simulated_annealing(problem, curve=True, random_state = random_state))\n",
    "    alg_names.append('simulated_annealing')\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.genetic_alg(problem, curve=True, max_iters=100, random_state=random_state))\n",
    "    \n",
    "    alg_names.append('genetic_algorithm')\n",
    "    problem = mlrose.DiscreteOpt(length = n, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "    problem.set_mimic_fast_mode(True)\n",
    "    algs.append(lambda: mlrose.mimic(problem,\n",
    "                                     curve=True, \n",
    "                                     random_state=random_state))\n",
    "    alg_names.append('mimic')\n",
    "    \n",
    "    thing = Runner(n, 'queens', algs, alg_names)\n",
    "    thing.run()\n",
    "    thing.print_stats()\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Fitting a Neural Network to the Heart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"data/heart.csv\")\n",
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    " # https://www.kaggle.com/ronitf/heart-disease-uci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(np.array(y_train).reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(np.array(y_test).reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNRunner:\n",
    "    def __init__(self, alg_names):\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.set_ylabel(\"Fitness score\")\n",
    "        ax1.set_xlabel(\"Iteration\")\n",
    "        self.fig1 = fig1\n",
    "        self.ax1 = ax1\n",
    "        \n",
    "        fig2, ax2 = plt.subplots()\n",
    "        ax2.set_ylabel(\"Fitness Evals\")\n",
    "        ax2.set_xlabel(\"Iterations\")\n",
    "        self.fig2 = fig2\n",
    "        self.ax2 = ax2\n",
    "        \n",
    "        self.names = alg_names\n",
    "        self.name = \"NN\"\n",
    "        self.times = []\n",
    "        self.scores = []\n",
    "        \n",
    "    def run(self):\n",
    "        for name in self.names:\n",
    "            print(f'starting {name}....')\n",
    "            tic = time.perf_counter()\n",
    "            print('===============================================')\n",
    "            print(f'running NN weight optimization for {name}')\n",
    "            # Initialize neural network object and fit object - attempt 1\n",
    "\n",
    "\n",
    "            schedule = mlrose.GeomDecay(.01,0.0001) \n",
    "            nn = mlrose.NeuralNetwork(hidden_nodes = [2], activation ='relu', \n",
    "                                             algorithm =name, \n",
    "                                             max_iters = 100, bias = False, is_classifier = True, \n",
    "                                             learning_rate = 0.0001, early_stopping = True,\n",
    "                                             schedule=schedule,\n",
    "                                             curve=True,\n",
    "                                             clip_max = 5, max_attempts = 1000, random_state = 5)\n",
    "            toc = time.perf_counter()\n",
    "            \n",
    "            nn.fit(X_train_scaled, y_train_hot)\n",
    "    \n",
    "            fitness_curve = nn.fitness_curve\n",
    "\n",
    "            # Predict labels for train set and assess accuracy\n",
    "            y_train_pred = nn.predict(X_train_scaled)\n",
    "\n",
    "            y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "            print(y_train_accuracy)\n",
    "\n",
    "            # Predict labels for test set and assess accuracy\n",
    "            y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "            y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "\n",
    "            print(y_test_accuracy)\n",
    "            print('\\n')\n",
    "            \n",
    "            self.times.append(toc-tic)\n",
    "            self.scores.append(y_test_accuracy)\n",
    "            self.plot_curve(fitness_curve, f'{name}')\n",
    "        \n",
    "        self.fig1.legend(loc=4)\n",
    "        self.fig2.legend(loc=4)\n",
    "        self.fig1.savefig(f'charts/{self.name}_{n}_items.png', bbox_inches='tight')\n",
    "        self.fig2.savefig(f'charts/{self.name}_{n}_items_evals.png', bbox_inches='tight')\n",
    "        self.fig1.clf()\n",
    "        self.fig2.clf()\n",
    "    \n",
    "    def print_stats(self):\n",
    "        for name, time, best_fitness in zip(self.names, self.times, self.best_fitnesses):\n",
    "            print(f'{name} had \\n\\tTime: {time:0.4f} seconds\\n\\tFitness Score: {best_fitness}')\n",
    "    def plot_curve(self, fitness_curve, name):\n",
    "        if len(fitness_curve.shape) == 2:\n",
    "            self.ax1.plot(range(0,len(fitness_curve)), fitness_curve[:,0], label=f'{name}')\n",
    "            self.ax2.plot(range(0,len(fitness_curve)), fitness_curve[:,1], label=f'{name}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting random_hill_climb....\n",
      "===============================================\n",
      "running NN weight optimization for random_hill_climb\n",
      "0.6239669421487604\n",
      "0.5573770491803278\n",
      "\n",
      "\n",
      "starting simulated_annealing....\n",
      "===============================================\n",
      "running NN weight optimization for simulated_annealing\n",
      "0.6239669421487604\n",
      "0.5573770491803278\n",
      "\n",
      "\n",
      "starting genetic_alg....\n",
      "===============================================\n",
      "running NN weight optimization for genetic_alg\n",
      "0.8471074380165289\n",
      "0.8360655737704918\n",
      "\n",
      "\n",
      "starting gradient_descent....\n",
      "===============================================\n",
      "running NN weight optimization for gradient_descent\n",
      "0.7231404958677686\n",
      "0.7213114754098361\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NNRunner.print_stats of <__main__.NNRunner object at 0x13f437520>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithms = ['random_hill_climb', 'simulated_annealing', 'genetic_alg','gradient_descent']\n",
    "\n",
    "runner_for_nn = NNRunner(algorithms)\n",
    "\n",
    "runner_for_nn.run()\n",
    "\n",
    "runner_for_nn.print_stats\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdd7e1c2594becc0f0730fd88e427749c52dec6ea015258dec14119a99cf0656"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
